{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCOIjQrGIfJf"
      },
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
        "!pip install tabpfn --quiet\n",
        "from tabpfn import TabPFNClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/sample_data/ReplicatedAcousticFeatures-ParkinsonDatabase.csv\")\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())"
      ],
      "metadata": {
        "id": "rYYoBml2Ig3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and labels\n",
        "X = df.drop(columns=[\"Status\"])\n",
        "y = df[\"Status\"]\n",
        "groups = df[\"ID\"]  # group by patient ID"
      ],
      "metadata": {
        "id": "vUe3a4mBI2Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouped split (train/test)\n",
        "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
        "for train_idx, test_idx in gss.split(X, y, groups):\n",
        "    X_train_full, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train_full, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "    groups_train = groups.iloc[train_idx]\n",
        "\n",
        "print(\"Train IDs:\", groups_train.nunique(), \"| Test IDs:\", groups.iloc[test_idx].nunique())"
      ],
      "metadata": {
        "id": "3PoVVeONI_So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Further split train into train/validation\n",
        "gss_val = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
        "for tr_idx, val_idx in gss_val.split(X_train_full, y_train_full, groups_train):\n",
        "    X_train, X_val = X_train_full.iloc[tr_idx], X_train_full.iloc[val_idx]\n",
        "    y_train, y_val = y_train_full.iloc[tr_idx], y_train_full.iloc[val_idx]\n",
        "\n",
        "print(f\"Shapes → Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "6itbQuyFJHYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep numeric columns only\n",
        "X_train = X_train.select_dtypes(include=[np.number])\n",
        "X_val = X_val.select_dtypes(include=[np.number])\n",
        "X_test = X_test.select_dtypes(include=[np.number])"
      ],
      "metadata": {
        "id": "K_0uU-gTJKJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection with Random Forest\n",
        "fs = SelectFromModel(RandomForestClassifier(n_estimators=500, random_state=42))\n",
        "fs.fit(X_train, y_train)\n",
        "\n",
        "selected_features = X_train.columns[fs.get_support()]\n",
        "print(f\"Selected features: {len(selected_features)} / {X_train.shape[1]}\")\n",
        "print(\"Top selected features:\", selected_features.tolist())\n",
        "\n",
        "# Transform datasets\n",
        "X_train_sel = pd.DataFrame(fs.transform(X_train), columns=selected_features)\n",
        "X_val_sel = pd.DataFrame(fs.transform(X_val), columns=selected_features)\n",
        "X_test_sel = pd.DataFrame(fs.transform(X_test), columns=selected_features)"
      ],
      "metadata": {
        "id": "2SmYxqvmJM5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MODEL 1: LIGHTGBM (Baseline)\n",
        "\n",
        "print(\"\\n================ LIGHTGBM BASELINE ================\\n\")\n",
        "\n",
        "lgbm = LGBMClassifier(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.01,\n",
        "    num_leaves=20,\n",
        "    min_child_samples=60,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=1.0,\n",
        "    reg_alpha=1.0,\n",
        "    reg_lambda=6.0,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgbm.fit(\n",
        "    X_train_sel, y_train,\n",
        "    eval_set=[(X_val_sel, y_val)],\n",
        "    eval_metric=\"logloss\",\n",
        "    callbacks=[early_stopping(100), log_evaluation(0)]\n",
        ")\n",
        "\n",
        "y_pred_test = lgbm.predict(X_test_sel)\n",
        "print(\"Train acc:\", accuracy_score(y_train, lgbm.predict(X_train_sel)))\n",
        "print(\"Test  acc:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"\\nTest report:\\n\", classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "XNWBudXxJRGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MODEL 2: SVM with PCA\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"\\n================ SVM MODEL ================\\n\")\n",
        "\n",
        "# Define the pipeline\n",
        "pipe_pca_svm = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA()),\n",
        "    (\"svc\", SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=42))\n",
        "])\n",
        "\n",
        "# Test effect of different PCA variance thresholds\n",
        "for comp in [0.90, 0.95, 0.98]:\n",
        "    pipe_pca_svm.set_params(\n",
        "        pca__n_components=comp,\n",
        "        svc__C=5,\n",
        "        svc__gamma=0.002\n",
        "    )\n",
        "    pipe_pca_svm.fit(X_train_sel, y_train)\n",
        "    test_acc = pipe_pca_svm.score(X_test_sel, y_test)\n",
        "    print(f\"PCA variance {comp*100:.0f}% → Test acc: {test_acc:.3f}\")\n",
        "\n",
        "# Train final model with best PCA\n",
        "best_svm = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=0.98)),\n",
        "    (\"svc\", SVC(kernel=\"rbf\", C=5, gamma=0.002, class_weight=\"balanced\", random_state=42))\n",
        "])\n",
        "\n",
        "best_svm.fit(X_train_sel, y_train)\n",
        "\n",
        "# Evaluate final model\n",
        "print(\"\\nFinal Evaluation:\")\n",
        "print(\"Train acc:\", accuracy_score(y_train, best_svm.predict(X_train_sel)))\n",
        "print(\"Test  acc:\", accuracy_score(y_test,  best_svm.predict(X_test_sel)))\n",
        "print(\"\\nClassification report (Test):\\n\", classification_report(y_test, best_svm.predict(X_test_sel)))"
      ],
      "metadata": {
        "id": "6QPSS-XZ1ja3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tabpfn"
      ],
      "metadata": {
        "id": "BGXTZwKS132k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabpfn import TabPFNClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"\\n================ TABPFN MODEL ================\\n\")\n",
        "\n",
        "tabpfn = TabPFNClassifier(device=\"cpu\")\n",
        "\n",
        "# Standardize the input\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_sel)\n",
        "X_test_scaled = scaler.transform(X_test_sel)\n",
        "\n",
        "# Fit and evaluate\n",
        "tabpfn.fit(X_train_scaled, y_train)\n",
        "y_pred_tabpfn = tabpfn.predict(X_test_scaled)\n",
        "\n",
        "print(\"Train acc:\", accuracy_score(y_train, tabpfn.predict(X_train_scaled)))\n",
        "print(\"Test acc:\", accuracy_score(y_test, y_pred_tabpfn))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_tabpfn))"
      ],
      "metadata": {
        "id": "phDhd6KnJaMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
        "logreg.fit(X_train_sel, y_train)\n",
        "\n",
        "print(\"Train acc:\", logreg.score(X_train_sel, y_train))\n",
        "print(\"Test  acc:\", logreg.score(X_test_sel, y_test))\n",
        "print(\"\\nReport:\\n\", classification_report(y_test, logreg.predict(X_test_sel)))"
      ],
      "metadata": {
        "id": "hZg5yyk72UOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Enable probability in your SVM\n",
        "svm_clf = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=0.98)),\n",
        "    (\"svc\", SVC(kernel=\"rbf\", C=5, gamma=0.002, class_weight=\"balanced\", probability=True, random_state=42))\n",
        "])\n",
        "svm_clf.fit(X_train_sel, y_train)\n",
        "\n",
        "\n",
        "# Ensemble fusion of LightGBM + SVM\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[('lgbm', lgbm), ('svm', svm_clf)],\n",
        "    voting='soft'\n",
        ")\n",
        "ensemble.fit(X_train_sel, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_ens = ensemble.predict(X_test_sel)\n",
        "print(\"\\n=== ENSEMBLE MODEL RESULTS ===\")\n",
        "print(\"Train acc:\", accuracy_score(y_train, ensemble.predict(X_train_sel)))\n",
        "print(\"Test  acc:\", accuracy_score(y_test, y_pred_ens))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_ens))\n"
      ],
      "metadata": {
        "id": "tcYy6T8oJ4XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define pipeline\n",
        "pipe_svm = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=0.98)),\n",
        "    (\"svc\", SVC(kernel=\"rbf\", class_weight=\"balanced\", probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "# Define search space\n",
        "param_grid = {\n",
        "    'svc__C': [1, 5, 10, 25, 50, 100],\n",
        "    'svc__gamma': [0.0005, 0.001, 0.002, 0.005, 0.01]\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "svm_grid = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "svm_grid.fit(X_train_sel, y_train)\n",
        "\n",
        "# Evaluate best model\n",
        "print(\"Best params:\", svm_grid.best_params_)\n",
        "print(\"Best CV acc:\", svm_grid.best_score_)\n",
        "print(\"Train acc:\", svm_grid.best_estimator_.score(X_train_sel, y_train))\n",
        "print(\"Test  acc:\", svm_grid.best_estimator_.score(X_test_sel, y_test))\n",
        "\n",
        "y_pred = svm_grid.best_estimator_.predict(X_test_sel)\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "tPBmYK4JJ7J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "print(\"\\n================ LOGISTIC REGRESSION (TUNED) ================\\n\")\n",
        "\n",
        "# Define pipeline\n",
        "pipe_log = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=0.98)),\n",
        "    (\"logreg\", LogisticRegression(class_weight='balanced', max_iter=5000, random_state=42))\n",
        "])\n",
        "\n",
        "\n",
        "# Define search space\n",
        "param_grid = {\n",
        "    'logreg__C': [0.5, 1, 2, 5, 10],\n",
        "    'logreg__solver': ['liblinear'],\n",
        "    'logreg__penalty': ['l2']\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "log_grid = GridSearchCV(pipe_log, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "log_grid.fit(X_train_sel, y_train)\n",
        "\n",
        "# Evaluate best model\n",
        "best_log = log_grid.best_estimator_\n",
        "y_pred_log = best_log.predict(X_test_sel)\n",
        "\n",
        "print(\"Best params:\", log_grid.best_params_)\n",
        "print(\"Best CV acc:\", log_grid.best_score_)\n",
        "print(\"Train acc:\", best_log.score(X_train_sel, y_train))\n",
        "print(\"Test  acc:\", best_log.score(X_test_sel, y_test))\n",
        "\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "id": "jogarJSFLCeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC CURVES FOR EACH MODEL\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "svm_clf = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=0.98)),\n",
        "    (\"svc\", SVC(kernel=\"rbf\", C=5, gamma=0.002, class_weight=\"balanced\",\n",
        "                probability=True, random_state=42))\n",
        "])\n",
        "svm_clf.fit(X_train_sel, y_train)\n",
        "\n",
        "# Predicted probabilities\n",
        "y_probs = {\n",
        "    \"LightGBM\": lgbm.predict_proba(X_test_sel)[:, 1],\n",
        "    \"SVM\": svm_clf.predict_proba(X_test_sel)[:, 1],\n",
        "    \"Logistic Regression\": best_log.predict_proba(X_test_sel)[:, 1],\n",
        "    \"TabPFN\": tabpfn.predict_proba(X_test_sel)[:, 1],\n",
        "    \"Ensemble\": ensemble.predict_proba(X_test_sel)[:, 1],\n",
        "}\n",
        "\n",
        "# ROC curves\n",
        "for model_name, y_prob in y_probs.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    auc_score = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label=f\"AUC = {auc_score:.3f}\")\n",
        "    plt.plot([0,1], [0,1], 'k--', lw=1.2)\n",
        "    plt.xlabel(\"False Positive Rate\", fontsize=11)\n",
        "    plt.ylabel(\"True Positive Rate\", fontsize=11)\n",
        "    plt.title(f\"ROC Curve — {model_name}\", fontsize=13, fontweight=\"bold\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "VnSpZ-iSJJqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# CONFUSION MATRIX - LIGHTGBM\n",
        "y_pred_lgbm = lgbm.predict(X_test_sel)\n",
        "cm_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
        "disp_lgbm = ConfusionMatrixDisplay(confusion_matrix=cm_lgbm, display_labels=['Healthy', 'Parkinson'])\n",
        "disp_lgbm.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix — LightGBM\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# CONFUSION MATRIX - SVM\n",
        "y_pred_svm = svm_clf.predict(X_test_sel)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "disp_svm = ConfusionMatrixDisplay(confusion_matrix=cm_svm, display_labels=['Healthy', 'Parkinson'])\n",
        "disp_svm.plot(cmap='Greens')\n",
        "plt.title(\"Confusion Matrix — SVM\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# CONFUSION MATRIX - LOGISTIC REGRESSION\n",
        "y_pred_log = best_log.predict(X_test_sel)\n",
        "cm_log = confusion_matrix(y_test, y_pred_log)\n",
        "disp_log = ConfusionMatrixDisplay(confusion_matrix=cm_log, display_labels=['Healthy', 'Parkinson'])\n",
        "disp_log.plot(cmap='Oranges')\n",
        "plt.title(\"Confusion Matrix — Logistic Regression\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# CONFUSION MATRIX - TABPFN\n",
        "y_pred_tab = tabpfn.predict(X_test_sel)\n",
        "cm_tab = confusion_matrix(y_test, y_pred_tab)\n",
        "disp_tab = ConfusionMatrixDisplay(confusion_matrix=cm_tab, display_labels=['Healthy', 'Parkinson'])\n",
        "disp_tab.plot(cmap='Purples')\n",
        "plt.title(\"Confusion Matrix — TabPFN\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SfPqBCWhJ251"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4UCCHFBAUBQJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}